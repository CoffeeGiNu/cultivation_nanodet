{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Load Nanodet in PyTorch\n",
    "\n",
    "This article is an introductory tutorial to infer nanodet with PyTorch.\n",
    "\n",
    "**Note**, we suppose this notebook is in the root directory of nonadet!\n",
    "\n",
    "## Install nanodet first\n",
    "\n",
    "For us to begin with, PyTorch should be installed. TorchVision is also required since we will be using it as our model zoo.\n",
    "\n",
    "A quick solution is to install via pip\n",
    "\n",
    "```shell\n",
    "pip install torch==1.7.1\n",
    "pip install torchvision==0.8.2\n",
    "```\n",
    "\n",
    "or please refer to official site https://pytorch.org/get-started/locally/\n",
    "\n",
    "PyTorch versions should be backwards compatible but should be used with the proper TorchVision version.\n",
    "\n",
    "And then don't forget to install other dependencies.\n",
    "\n",
    "```shell\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "Next enter the key part, let's install `nanodet`!\n",
    "\n",
    "```shell\n",
    "python setup.py develop\n",
    "```\n",
    "\n",
    "## Set Environmental Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model Configuration and Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanodet.util import cfg, load_config, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "config_path = '/home/studio-lab-user/cultivation_nanodet/config/my_nanodet-m_sage.yml'\n",
    "model_path = '/home/studio-lab-user/cultivation_nanodet/workspace/nanodet_m/model_best/model_best.ckpt'\n",
    "image_path = '/home/studio-lab-user/cultivation_nanodet/demo_mnn/imgs/rgb_2.png'"
=======
    "config_path = 'config/my_nanodet-m_sage.yml'\n",
    "model_path = 'workspace/nanodet_m/state_dict.pth'\n",
    "image_path = 'demo_mnn/imgs/rgb_2.png'"
>>>>>>> 53f79d787e0ecc8bcb7973ff56e624bda1b94aec
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_config(cfg, config_path)\n",
    "logger = Logger(-1, use_tensorboard=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Model Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from demo.demo import Predictor\n",
    "from demo import Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size is  1.0x\n",
      "init weights...\n",
      "=> loading pretrained model https://dl.dropboxusercontent.com/s/1ubzkkfpsxxug10/checkpoint%20%281%29.pth\n",
      "Finish initialize NanoDet Head.\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(cfg, model_path, logger, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward time: 1.470s | decode time: 0.056s | "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/nanodet/lib/python3.8/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/nanodet/lib/python3.8/site-packages/torch/nn/functional.py:3679: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\n",
      "/home/studio-lab-user/.conda/envs/nanodet/lib/python3.8/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /opt/conda/conda-bld/pytorch_1634272172048/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "meta, res = predictor.inference(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection output visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nanodet.util import overlay_bbox_cv\n",
    "\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "def cv2_imshow(a, convert_bgr_to_rgb=True):\n",
    "    \"\"\"A replacement for cv2.imshow() for use in Jupyter notebooks.\n",
    "    Args:\n",
    "        a: np.ndarray. shape (N, M) or (N, M, 1) is an NxM grayscale image. shape\n",
    "            (N, M, 3) is an NxM BGR color image. shape (N, M, 4) is an NxM BGRA color\n",
    "            image.\n",
    "        convert_bgr_to_rgb: switch to convert BGR to RGB channel.\n",
    "    \"\"\"\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    # cv2 stores colors as BGR; convert to RGB\n",
    "    if convert_bgr_to_rgb and a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    display(Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-263dbd37918b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moverlay_bbox_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'raw_img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_thresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/cultivation_nanodet/nanodet/util/visualization.py\u001b[0m in \u001b[0;36moverlay_bbox_cv\u001b[0;34m(img, dets, class_names, score_thresh)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mfont\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtxt_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetTextSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         cv2.rectangle(\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.4) :-1: error: (-5:Bad argument) in function 'rectangle'\n> Overload resolution failed:\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n>  - img is not a numpy array, neither a scalar\n>  - Expected Ptr<cv::UMat> for argument 'img'\n"
     ]
    }
   ],
   "source": [
    "result = overlay_bbox_cv(meta['raw_img'], res[0], cfg.class_names, score_thresh=0.35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_scale = 1.0\n",
    "cv2_imshow(cv2.resize(result, None, fx=imshow_scale, fy=imshow_scale))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "YOLOv5 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nanodet:Python",
   "language": "python",
   "name": "conda-env-nanodet-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
